{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "geological-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import re\n",
    "import os, sys\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import spacy\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from config import SEED, PARTIAL_TRAIN, TEST_SIZE, NUM_LABELS \n",
    "from config import MAX_SEQUENCE_LENGTH, NUM_EPOCH, LEARNING_RATE, BATCH_SIZE\n",
    "from config import ACCUMULATION_STEPS, INPUT_DIR, WORK_DIR, TOXICITY_COLUMN, DATA_DIR\n",
    "from config import BERT_MODEL_NAME, FINE_TUNED_MODEL_PATH\n",
    "\n",
    "from utils import set_seed, convert_lines_onfly, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brazilian-approval",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "## instantiate bert pretrained model and tokenizer\n",
    "toxic_model = BertForSequenceClassification.from_pretrained(BERT_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "toxic_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "## load saved model\n",
    "toxic_model.load_state_dict(torch.load(FINE_TUNED_MODEL_PATH)) \n",
    "for p in toxic_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "## use gpu\n",
    "toxic_model.cuda()\n",
    "\n",
    "def predict_toxicity(sentence: str) -> float :\n",
    "    \"\"\"\n",
    "    predict the toxicity level from a sentence\n",
    "    \"\"\"    \n",
    "\n",
    "    toxic_model.eval()\n",
    "    \n",
    "    X = np.array([str(sentence)])\n",
    "    test_preds = torch.zeros((len(X)))\n",
    "    \n",
    "    Xp = convert_lines_onfly(X, MAX_SEQUENCE_LENGTH, toxic_tokenizer)\n",
    "    y_pred = toxic_model(torch.from_numpy(Xp).to(device)).logits\n",
    "    test_preds[0] = test_preds[0] + torch.sigmoid(y_pred[0,0].cpu())\n",
    "\n",
    "    return float(test_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hindu-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess_sentiment(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task = 'sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# label mapping\n",
    "NEG = 'negative'\n",
    "NET = 'neutral'\n",
    "POS = 'positive'\n",
    "labels = [NEG, NET, POS]\n",
    "\n",
    "label2id = {k:v for k, v in zip(labels, range(3))}\n",
    "id2label = {k:v for k, v in zip(range(3), labels)}\n",
    "\n",
    "def predict_sentiment(sentence: str) :\n",
    "    text = preprocess_sentiment(sentence)\n",
    "    encoded_input = sentiment_tokenizer(text, return_tensors='pt')\n",
    "    output = sentiment_model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    sentiment = {id2label[idx]:s for idx, s in enumerate(scores)}\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ranging-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def split_text(sentence): \n",
    "    doc = nlp(sentence)\n",
    "    sentences = [sent.string.strip() for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "boolean-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Oh sh*t!! What an awesome goal, I nearly missed it…\"\n",
    "# sentence = \"Yet call out all Muslims for the acts of a few will get you pilloried.   So why is it okay to smear an entire religion over these few idiots?  Or is this because it's okay to bash Christian sects?\"\n",
    "# sentence = \"Sorry to have to do this, but just to see if profanity filtering is enabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bound-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Oh sh*t!! What an awesome goal, I nearly missed it…\n",
      "Toxicity:  0.673354983329773\n",
      "Sentiment:  {'negative': 0.21319842, 'neutral': 0.23147435, 'positive': 0.5553271}\n",
      "Splitted Sentence:  ['Oh sh*t!!', 'What an awesome goal, I nearly missed it…']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence: \", sentence)\n",
    "print(\"Toxicity: \", predict_toxicity(sentence))\n",
    "print(\"Sentiment: \", predict_sentiment(sentence))\n",
    "print(\"Splitted Sentence: \", split_text(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "placed-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_edge_case(sentence: str, toxic_threshold=0.3) -> float :\n",
    "    sentences = split_text(sentence)\n",
    "    for i in range(len(sentences)) :\n",
    "        truncated = \" \".join(sentences[:i] + sentences[i+1:])\n",
    "        toxicity = predict_toxicity(truncated)\n",
    "        sentiment = predict_sentiment(truncated)\n",
    "        if toxicity < toxic_threshold and sentiment[POS] > sentiment[NEG] :\n",
    "            return toxicity\n",
    "    return predict_toxicity(sentence)\n",
    "\n",
    "def predict_with_combined_toxicity_sentiment(sentence: str) -> float :\n",
    "    toxicity = predict_toxicity(sentence)\n",
    "    sentiment = predict_sentiment(sentence)\n",
    "    \n",
    "    score = toxicity\n",
    "    \n",
    "    if toxicity > 0.9 :\n",
    "        if sentiment[NEG] > sentiment[POS] :\n",
    "            score = toxicity\n",
    "        else :\n",
    "            score = handle_edge_case(sentence, toxic_threshold=0.1)\n",
    "    elif toxicity > 0.3 :\n",
    "        if sentiment[NEG] > sentiment[POS] :\n",
    "            score = toxicity\n",
    "        else :\n",
    "            score = handle_edge_case(sentence, toxic_threshold=0.5)\n",
    "    else : # toxicity < 0.3\n",
    "        score = toxicity\n",
    "            \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "subsequent-retention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033970933873206377"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_with_combined_toxicity_sentiment(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-aircraft",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
